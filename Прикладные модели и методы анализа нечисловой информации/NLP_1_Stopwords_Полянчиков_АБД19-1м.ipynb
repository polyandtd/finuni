{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_1_Stopwords.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjU9Gl_7Wcdp",
        "colab_type": "text"
      },
      "source": [
        "## Полянчиков Владислав АБД19-1м\n",
        "\n",
        "#### Занятие 1. Выделение стоп слов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIfjHSfOWEU_",
        "colab_type": "text"
      },
      "source": [
        "- Взать кусок текста размером 1 лист экономической направленности\n",
        "- Выделить стоп слова тремя различными способами\n",
        "- Сравнить результаты \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ha_HO87-WYwj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "import spacy\n",
        "import gensim"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B72Ew3TIWqSb",
        "colab_type": "text"
      },
      "source": [
        "#### 1. Выделение стоп слов методом spacy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKcgV-P2Woop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load('en')\n",
        "doc = nlp('The pan-European Stoxx 600 ended down 1.1%, having fluctuated throughout the day. Technology stocks led the losses, down 2.6%, while Europe’s banking index jumped 1.6%. Markets had looked to be rebounding from Thursday’s tumble stateside but ran out of steam as the session progressed. The Dow Jones Industrial Average on Thursday plunged 521 points, or 2.8%, to record its steepest single-day losses since June, while the S&P 500 plunged 3.5% and the Nasdaq Composite dropped 5%. Tech mega stocks Apple, Amazon, Netflix, Alphabet and Facebook led the losses with the broad tech sector posting its worst day since March, having driven much of Wall Street’s recovery in recent months. U.S. stocks extended losses on Friday. Thursday’s losses spilled over into Asia Pacific trading overnight, with Australia’s S&P/ASX 200 falling more than 3% on Friday while tech stocks fueled declines of more than 1% for the majority of Asian markets.')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fX3zacSmXRvU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "3a080f2a-b42b-4cfe-c98f-99d12560373f"
      },
      "source": [
        "i=0\n",
        "for token in doc:\n",
        "    print(token)\n",
        "    i+=1\n",
        "    if i ==5:\n",
        "      break"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The\n",
            "pan\n",
            "-\n",
            "European\n",
            "Stoxx\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zO87zgs5XyGz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        },
        "outputId": "c5fd36be-7d2f-43b3-ef95-020cb3c42bc6"
      },
      "source": [
        "print(f\"Token \\t\\t\\t\\tLemma \\t\\t\\t\\tStopword\".format('Token', 'Lemma', 'Stopword'))\n",
        "print(\"-\"*60)\n",
        "i = 0\n",
        "for token in doc:\n",
        "    print(f\"{str(token)}\\t\\t\\t\\t{token.lemma_}\\t\\t\\t\\t{token.is_stop}\")\n",
        "    i+=1\n",
        "    if i ==50:\n",
        "      break"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token \t\t\t\tLemma \t\t\t\tStopword\n",
            "------------------------------------------------------------\n",
            "The\t\t\t\tthe\t\t\t\tTrue\n",
            "pan\t\t\t\tpan\t\t\t\tFalse\n",
            "-\t\t\t\t-\t\t\t\tFalse\n",
            "European\t\t\t\tEuropean\t\t\t\tFalse\n",
            "Stoxx\t\t\t\tStoxx\t\t\t\tFalse\n",
            "600\t\t\t\t600\t\t\t\tFalse\n",
            "ended\t\t\t\tend\t\t\t\tFalse\n",
            "down\t\t\t\tdown\t\t\t\tTrue\n",
            "1.1\t\t\t\t1.1\t\t\t\tFalse\n",
            "%\t\t\t\t%\t\t\t\tFalse\n",
            ",\t\t\t\t,\t\t\t\tFalse\n",
            "having\t\t\t\thave\t\t\t\tFalse\n",
            "fluctuated\t\t\t\tfluctuate\t\t\t\tFalse\n",
            "throughout\t\t\t\tthroughout\t\t\t\tTrue\n",
            "the\t\t\t\tthe\t\t\t\tTrue\n",
            "day\t\t\t\tday\t\t\t\tFalse\n",
            ".\t\t\t\t.\t\t\t\tFalse\n",
            "Technology\t\t\t\ttechnology\t\t\t\tFalse\n",
            "stocks\t\t\t\tstock\t\t\t\tFalse\n",
            "led\t\t\t\tlead\t\t\t\tFalse\n",
            "the\t\t\t\tthe\t\t\t\tTrue\n",
            "losses\t\t\t\tloss\t\t\t\tFalse\n",
            ",\t\t\t\t,\t\t\t\tFalse\n",
            "down\t\t\t\tdown\t\t\t\tTrue\n",
            "2.6\t\t\t\t2.6\t\t\t\tFalse\n",
            "%\t\t\t\t%\t\t\t\tFalse\n",
            ",\t\t\t\t,\t\t\t\tFalse\n",
            "while\t\t\t\twhile\t\t\t\tTrue\n",
            "Europe\t\t\t\tEurope\t\t\t\tFalse\n",
            "’s\t\t\t\t’s\t\t\t\tTrue\n",
            "banking\t\t\t\tbanking\t\t\t\tFalse\n",
            "index\t\t\t\tindex\t\t\t\tFalse\n",
            "jumped\t\t\t\tjump\t\t\t\tFalse\n",
            "1.6\t\t\t\t1.6\t\t\t\tFalse\n",
            "%\t\t\t\t%\t\t\t\tFalse\n",
            ".\t\t\t\t.\t\t\t\tFalse\n",
            "Markets\t\t\t\tmarket\t\t\t\tFalse\n",
            "had\t\t\t\thave\t\t\t\tTrue\n",
            "looked\t\t\t\tlook\t\t\t\tFalse\n",
            "to\t\t\t\tto\t\t\t\tTrue\n",
            "be\t\t\t\tbe\t\t\t\tTrue\n",
            "rebounding\t\t\t\trebound\t\t\t\tFalse\n",
            "from\t\t\t\tfrom\t\t\t\tTrue\n",
            "Thursday\t\t\t\tThursday\t\t\t\tFalse\n",
            "’s\t\t\t\t’s\t\t\t\tTrue\n",
            "tumble\t\t\t\ttumble\t\t\t\tFalse\n",
            "stateside\t\t\t\tstateside\t\t\t\tFalse\n",
            "but\t\t\t\tbut\t\t\t\tTrue\n",
            "ran\t\t\t\trun\t\t\t\tFalse\n",
            "out\t\t\t\tout\t\t\t\tTrue\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B91z4xNb12K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d4f9052e-71c7-4569-b395-6f46a9eea3b6"
      },
      "source": [
        "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
        "print('Number of stop words: %d' % len(spacy_stopwords))\n",
        "print('First ten stop words: %s' % list(spacy_stopwords)[:10])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of stop words: 326\n",
            "First ten stop words: [\"'d\", 'latterly', 'mine', 'hereby', 'thereafter', \"'ve\", 'therefore', 'were', \"n't\", 'elsewhere']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dn6QWrseaulD",
        "colab_type": "text"
      },
      "source": [
        "### 2. Выведение стоп слов с помощью библиотеки nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1VFDnuea1lJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "de582f0f-7adb-4063-991f-f8f1edb2c388"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bH2Fca7UbEYA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "bfe015ec-8404-49ce-f5fc-96a5d1adc00f"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "#print(stopwords.words('english'))\n",
        "print('Number of stop words: %d' % len(stopwords.words('english')))\n",
        "print('First twenty stop words: %s' % list(stopwords.words('english'))[:20])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of stop words: 179\n",
            "First twenty stop words: ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaviTiUUc-_v",
        "colab_type": "text"
      },
      "source": [
        "### 3. Выведение методом библиотеки Gensim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G509BxPadDo6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "63fe2b2c-6eb5-4999-be55-28dbfbf7a1fe"
      },
      "source": [
        "import gensim\n",
        "gensim_stopwords = gensim.parsing.preprocessing.STOPWORDS\n",
        "\n",
        "print('Number of stop words: %d' % len(gensim_stopwords))\n",
        "print('First twenty stop words: %s' % list(gensim_stopwords)[:20])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of stop words: 337\n",
            "First twenty stop words: ['thereafter', 'latterly', 'mine', 'hereby', 'were', 'therefore', 'elsewhere', 'over', 'must', 'again', 'without', 'if', 'whatever', 'only', 'beforehand', 'formerly', 'been', 'really', 'into', 'me']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5j4KLDuZaYV",
        "colab_type": "text"
      },
      "source": [
        "### Сравнения\n",
        "\n",
        "- Библиотека Spacy не поддерживает русский язык\n",
        "- у nltk почти в два раза меньше стоп слов (!), чем у spacy\n",
        "- gensim (сегодня оказался новой для меня библиотекой) вобрал в себя наибольшее количество стоп слов"
      ]
    }
  ]
}