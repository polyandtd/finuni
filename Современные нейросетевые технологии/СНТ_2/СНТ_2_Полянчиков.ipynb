{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "СНТ_2_Полянчиков.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ehTK6t490fIt"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrUuSrPSX7-i",
        "colab_type": "text"
      },
      "source": [
        "### Задания по лекции 2. Полянчиков Владислав, АБД19-1м"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aA54hHPxt6jB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "06a87115-4e0a-4afe-cc9b-fca1acc57121"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow import keras\n",
        "import keras.layers as layers\n",
        "from keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPooling2D\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('./gdrive/My Drive/finuni/SNT/my_conv_model') # загрузка сохраненнлй модели\n",
        "#model.save('./gdrive/My Drive/finuni/SNT/my_conv_model')\n",
        "\n",
        "\n",
        "print(\"Setup Complete\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "4/4AG9YElTi3NjkndrU5KXOa3QuYnKp258jfRoIEIqgBPCGQWJ60_PrDA\n",
            "Mounted at /content/gdrive\n",
            "Setup Complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bxj942c7mre9",
        "colab_type": "text"
      },
      "source": [
        "### Задание 2\n",
        "создайте многослойный персептрон и сверточную сеть для\n",
        "классификации данных fashion_mnist (cifar10), оцените точность полученных\n",
        "результатов и ошибки по классам. Сохраните модель, сохраните\n",
        "наиболее эффективные веса."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dx6yM7nFnAeV",
        "colab_type": "text"
      },
      "source": [
        "### Задание 3. \n",
        "Продемонстрируйте работу обратных вызовов в процессе обучения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_iCuRk5Lfc1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a32a80cd-02d5-4c47-9f82-07db3cec3e47"
      },
      "source": [
        "model = load_model('./gdrive/My Drive/finuni/SNT/my_conv_model_nadam')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.sequential.Sequential at 0x7f08c3d9c198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cE5HpH6N1o20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLdnl2WI1z41",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "b625aff3-8219-4fab-ec35-ff2f40289e8a"
      },
      "source": [
        "idx = 155\n",
        "print(y_train[idx])\n",
        "plt.imshow(X_train[idx]);"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[8]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xmb3NTNL12gM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f6cc42a7-a155-4ba0-fe94-69bb84a168b2"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNxbpSXM1--w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(42)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4qh_pZQ2PgA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(42)\n",
        "NB_EPOCH = 200 \n",
        "BATCH_SIZE = 128 \n",
        "VERBOSE = 1 \n",
        "NB_CLASSES = 10\n",
        "OPTIMIZER = SGD()\n",
        "N_HIDDEN = 128\n",
        "VALIDATION_SPLIT = 0.2 \n",
        "\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "X_test2 = X_test.copy()\n",
        "y_test2 = y_test.copy()\n",
        "y_train2 = y_train.copy()\n",
        "# RESHAPED = 784\n",
        "# X_train = X_train.reshape(60000, RESHAPED)\n",
        "# X_test = X_test.reshape(10000, RESHAPED)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, NB_CLASSES)\n",
        "y_test = keras.utils.to_categorical(y_test, NB_CLASSES)"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iPp1abQ2hoR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9080a710-54df-4ab9-84aa-e9144593df7a"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBHub90F2R2q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1c576748-519b-4d42-9e5e-87cce2760201"
      },
      "source": [
        "print(X_train.shape[0], 'train_samples')\n",
        "print(X_test.shape[0], 'test_samples')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000 train_samples\n",
            "10000 test_samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "937koJrd2quU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "keras.Input(shape=(32,32,1)),\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation=\"relu\"))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation=\"relu\"))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(NB_CLASSES, activation='softmax'))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4B9u20hjwC7w",
        "colab_type": "text"
      },
      "source": [
        "###### используются параметры выше, но клетка не активирована, так как я перезагружал блокнот, чтобы переставить на GPU для более быстрого обучения. После загрузил предварительно сохраненную модель из google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2E9u2Ldk2-ao",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "outputId": "2f763b99-b156-40a0-eb32-bf2ebddba14e"
      },
      "source": [
        "callback = keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics='accuracy')\n",
        "\n",
        "model.fit(X_train, y_train, batch_size=250, epochs=15, verbose = 1, callbacks=[callback], validation_split=0.3)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "  2/140 [..............................] - ETA: 6s - loss: 2.3332 - accuracy: 0.1000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0114s vs `on_train_batch_end` time: 0.0760s). Check your callbacks.\n",
            "140/140 [==============================] - ETA: 0s - loss: 1.9641 - accuracy: 0.2812WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0027s vs `on_test_batch_end` time: 0.0112s). Check your callbacks.\n",
            "140/140 [==============================] - 11s 77ms/step - loss: 1.9641 - accuracy: 0.2812 - val_loss: 1.6979 - val_accuracy: 0.4083\n",
            "Epoch 2/15\n",
            "140/140 [==============================] - 10s 74ms/step - loss: 1.5447 - accuracy: 0.4444 - val_loss: 1.4569 - val_accuracy: 0.5015\n",
            "Epoch 3/15\n",
            "140/140 [==============================] - 10s 74ms/step - loss: 1.3903 - accuracy: 0.5054 - val_loss: 1.3539 - val_accuracy: 0.5384\n",
            "Epoch 4/15\n",
            "140/140 [==============================] - 10s 74ms/step - loss: 1.2851 - accuracy: 0.5421 - val_loss: 1.2275 - val_accuracy: 0.5839\n",
            "Epoch 5/15\n",
            "140/140 [==============================] - 10s 74ms/step - loss: 1.2105 - accuracy: 0.5706 - val_loss: 1.1587 - val_accuracy: 0.6087\n",
            "Epoch 6/15\n",
            "140/140 [==============================] - 10s 75ms/step - loss: 1.1378 - accuracy: 0.5953 - val_loss: 1.1343 - val_accuracy: 0.6139\n",
            "Epoch 7/15\n",
            "140/140 [==============================] - 10s 74ms/step - loss: 1.0944 - accuracy: 0.6130 - val_loss: 1.0596 - val_accuracy: 0.6401\n",
            "Epoch 8/15\n",
            "140/140 [==============================] - 10s 74ms/step - loss: 1.0485 - accuracy: 0.6302 - val_loss: 1.0314 - val_accuracy: 0.6478\n",
            "Epoch 9/15\n",
            "140/140 [==============================] - 10s 75ms/step - loss: 1.0089 - accuracy: 0.6455 - val_loss: 1.0017 - val_accuracy: 0.6670\n",
            "Epoch 10/15\n",
            "140/140 [==============================] - 10s 75ms/step - loss: 0.9766 - accuracy: 0.6561 - val_loss: 0.9544 - val_accuracy: 0.6760\n",
            "Epoch 11/15\n",
            "140/140 [==============================] - 10s 74ms/step - loss: 0.9491 - accuracy: 0.6665 - val_loss: 0.9303 - val_accuracy: 0.6841\n",
            "Epoch 12/15\n",
            "140/140 [==============================] - 10s 74ms/step - loss: 0.9228 - accuracy: 0.6765 - val_loss: 0.9049 - val_accuracy: 0.6965\n",
            "Epoch 13/15\n",
            "140/140 [==============================] - 10s 74ms/step - loss: 0.8970 - accuracy: 0.6850 - val_loss: 0.9228 - val_accuracy: 0.6888\n",
            "Epoch 14/15\n",
            "140/140 [==============================] - 10s 74ms/step - loss: 0.8793 - accuracy: 0.6931 - val_loss: 0.8627 - val_accuracy: 0.7069\n",
            "Epoch 15/15\n",
            "140/140 [==============================] - 10s 74ms/step - loss: 0.8633 - accuracy: 0.6995 - val_loss: 0.8518 - val_accuracy: 0.7112\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4098bd3898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehTK6t490fIt",
        "colab_type": "text"
      },
      "source": [
        "###### После первых 15 эпох результат был в районе 20-30 % (SGD)\n",
        "###### С Адамом - около 70%\n",
        "###### С Адамом + Нестеровым - 71%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8R8ZmyyvLCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=150, epochs=30, verbose = 1, callbacks=[callback], validation_split=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9WiRtVzvhec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=100, epochs=30, verbose = 1, callbacks=[callback], validation_split=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3FmuuUMwt6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callback = keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
        "model.fit(X_train, y_train, batch_size=250, epochs=30, verbose = 1, callbacks=[callback], validation_split=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WZBopmOKXxa",
        "colab_type": "text"
      },
      "source": [
        "##### Первый callback!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AY8XmwmlxRhQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 888
        },
        "outputId": "9257d359-1a53-4294-f056-4502f6eb4377"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=500, epochs=30, verbose = 1, callbacks=[callback], validation_split=0.3)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "70/70 [==============================] - 9s 133ms/step - loss: 0.5128 - accuracy: 0.8167 - val_loss: 0.6458 - val_accuracy: 0.7775\n",
            "Epoch 2/30\n",
            "70/70 [==============================] - 9s 131ms/step - loss: 0.5115 - accuracy: 0.8162 - val_loss: 0.6362 - val_accuracy: 0.7801\n",
            "Epoch 3/30\n",
            "70/70 [==============================] - 9s 131ms/step - loss: 0.5034 - accuracy: 0.8191 - val_loss: 0.6345 - val_accuracy: 0.7807\n",
            "Epoch 4/30\n",
            "70/70 [==============================] - 9s 131ms/step - loss: 0.5072 - accuracy: 0.8199 - val_loss: 0.6343 - val_accuracy: 0.7808\n",
            "Epoch 5/30\n",
            "70/70 [==============================] - 9s 131ms/step - loss: 0.5027 - accuracy: 0.8217 - val_loss: 0.6315 - val_accuracy: 0.7821\n",
            "Epoch 6/30\n",
            "70/70 [==============================] - 9s 131ms/step - loss: 0.5048 - accuracy: 0.8200 - val_loss: 0.6383 - val_accuracy: 0.7788\n",
            "Epoch 7/30\n",
            "70/70 [==============================] - 9s 131ms/step - loss: 0.5031 - accuracy: 0.8200 - val_loss: 0.6378 - val_accuracy: 0.7805\n",
            "Epoch 8/30\n",
            "70/70 [==============================] - 9s 131ms/step - loss: 0.5045 - accuracy: 0.8217 - val_loss: 0.6382 - val_accuracy: 0.7791\n",
            "Epoch 9/30\n",
            "70/70 [==============================] - 9s 131ms/step - loss: 0.5049 - accuracy: 0.8193 - val_loss: 0.6381 - val_accuracy: 0.7803\n",
            "Epoch 10/30\n",
            "70/70 [==============================] - 9s 131ms/step - loss: 0.5015 - accuracy: 0.8197 - val_loss: 0.6376 - val_accuracy: 0.7788\n",
            "Epoch 11/30\n",
            "70/70 [==============================] - 9s 131ms/step - loss: 0.5048 - accuracy: 0.8191 - val_loss: 0.6338 - val_accuracy: 0.7801\n",
            "Epoch 12/30\n",
            "70/70 [==============================] - 9s 131ms/step - loss: 0.5102 - accuracy: 0.8187 - val_loss: 0.6378 - val_accuracy: 0.7809\n",
            "Epoch 13/30\n",
            "70/70 [==============================] - 9s 131ms/step - loss: 0.5006 - accuracy: 0.8221 - val_loss: 0.6329 - val_accuracy: 0.7839\n",
            "Epoch 14/30\n",
            "70/70 [==============================] - 9s 132ms/step - loss: 0.5042 - accuracy: 0.8195 - val_loss: 0.6310 - val_accuracy: 0.7846\n",
            "Epoch 15/30\n",
            "70/70 [==============================] - 9s 131ms/step - loss: 0.5009 - accuracy: 0.8230 - val_loss: 0.6284 - val_accuracy: 0.7865\n",
            "Epoch 16/30\n",
            "70/70 [==============================] - 9s 131ms/step - loss: 0.5063 - accuracy: 0.8203 - val_loss: 0.6261 - val_accuracy: 0.7841\n",
            "Epoch 17/30\n",
            "70/70 [==============================] - 9s 131ms/step - loss: 0.5053 - accuracy: 0.8205 - val_loss: 0.6394 - val_accuracy: 0.7789\n",
            "Epoch 18/30\n",
            "70/70 [==============================] - 9s 131ms/step - loss: 0.4984 - accuracy: 0.8240 - val_loss: 0.6386 - val_accuracy: 0.7823\n",
            "Epoch 19/30\n",
            "70/70 [==============================] - 9s 131ms/step - loss: 0.4960 - accuracy: 0.8236 - val_loss: 0.6406 - val_accuracy: 0.7803\n",
            "Epoch 20/30\n",
            "70/70 [==============================] - 9s 131ms/step - loss: 0.5033 - accuracy: 0.8197 - val_loss: 0.6359 - val_accuracy: 0.7801\n",
            "Epoch 21/30\n",
            "70/70 [==============================] - 9s 131ms/step - loss: 0.4985 - accuracy: 0.8221 - val_loss: 0.6371 - val_accuracy: 0.7807\n",
            "Epoch 22/30\n",
            "70/70 [==============================] - 9s 131ms/step - loss: 0.5019 - accuracy: 0.8199 - val_loss: 0.6304 - val_accuracy: 0.7855\n",
            "Epoch 23/30\n",
            "70/70 [==============================] - 9s 131ms/step - loss: 0.4999 - accuracy: 0.8209 - val_loss: 0.6346 - val_accuracy: 0.7811\n",
            "Epoch 24/30\n",
            "70/70 [==============================] - 9s 131ms/step - loss: 0.4983 - accuracy: 0.8219 - val_loss: 0.6288 - val_accuracy: 0.7841\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4094f05518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87glZVUr1Hh2",
        "colab_type": "text"
      },
      "source": [
        "###### Кажется, выжали максимум. Можно сохранять.\n",
        "Лучший результат на валидационной выборке - 77.07% (с оптимизатором SGD. Сейчас на том же месте прогоню с Адамом)\n",
        "\n",
        "По итогу, Адам обучался быстрее, однако добился несколько худшего результата на валидационной выборке при прочих равных - 76.83%\n",
        "\n",
        "Модель с оптимизатором Адама-Нестерова обучалась гораздо быстрее обеих предыдущих. Также быстрее случился первый коллбэк. Однако модель со временем начала переобучаться (я слегка изменил значения Дропаута). Имеет однозначно лучший показатель по потерям (vby 0.496 против 0.65 Адама), а также все показатели accuracy 82.4 % на train и 78.65 % на валидационной!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fogYP1rleTsG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9156ff38-030b-40aa-c104-ce0f9c7339c9"
      },
      "source": [
        "model.save('./gdrive/My Drive/finuni/SNT/my_conv_model_nadam')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./gdrive/My Drive/finuni/SNT/my_conv_model_nadam/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rCy_kYKTz0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_adam = load_model('./gdrive/My Drive/finuni/SNT/my_conv_model_adam')\n",
        "model = load_model('./gdrive/My Drive/finuni/SNT/my_conv_model')"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_-Cef4wUXVu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(50)\n",
        "pred_nadam = model.predict(X_test)\n",
        "pred_adam = model_adam.predict(X_test)\n",
        "pred_model1 = model1.predict(X_test)\n",
        "\n",
        "pred_nadam = [np.argmax(i) for i in pred_nadam]\n",
        "pred_adam = [np.argmax(i) for i in pred_adam]\n",
        "pred_model1 = [np.argmax(i) for i in pred_model1]"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9ACC69ma_TF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "ba7aeb9c-f7c2-4cbb-dc70-6abc3a12d97d"
      },
      "source": [
        "y_train2"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6],\n",
              "       [9],\n",
              "       [9],\n",
              "       ...,\n",
              "       [9],\n",
              "       [1],\n",
              "       [1]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjOm3wE8Vpk2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "a17811c0-2843-4e57-f566-e2e280bfb690"
      },
      "source": [
        "y_test2"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3],\n",
              "       [8],\n",
              "       [8],\n",
              "       ...,\n",
              "       [5],\n",
              "       [1],\n",
              "       [7]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuvLDzKhUm8b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "nadam_score = accuracy_score(pred_nadam, y_test2)\n",
        "adam_score = accuracy_score(pred_adam, y_test2)\n",
        "model1_score = accuracy_score(pred_model1, y_test2)"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCQGR693VujP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "195dc2cd-18e7-4cf6-8cb6-c7b78ed71a31"
      },
      "source": [
        "nadam_score, adam_score, model1_score"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7695, 0.7643, 0.7695)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsHy8cm3blp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "results = pd.DataFrame()\n",
        "results['Nadam'] = pred_nadam\n",
        "results['Adam'] = pred_adam\n",
        "results['Model1'] = pred_model1"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwJjdtmacZJc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "outputId": "697931aa-554b-4385-ad4a-2a74faa53c34"
      },
      "source": [
        "results.T"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>9960</th>\n",
              "      <th>9961</th>\n",
              "      <th>9962</th>\n",
              "      <th>9963</th>\n",
              "      <th>9964</th>\n",
              "      <th>9965</th>\n",
              "      <th>9966</th>\n",
              "      <th>9967</th>\n",
              "      <th>9968</th>\n",
              "      <th>9969</th>\n",
              "      <th>9970</th>\n",
              "      <th>9971</th>\n",
              "      <th>9972</th>\n",
              "      <th>9973</th>\n",
              "      <th>9974</th>\n",
              "      <th>9975</th>\n",
              "      <th>9976</th>\n",
              "      <th>9977</th>\n",
              "      <th>9978</th>\n",
              "      <th>9979</th>\n",
              "      <th>9980</th>\n",
              "      <th>9981</th>\n",
              "      <th>9982</th>\n",
              "      <th>9983</th>\n",
              "      <th>9984</th>\n",
              "      <th>9985</th>\n",
              "      <th>9986</th>\n",
              "      <th>9987</th>\n",
              "      <th>9988</th>\n",
              "      <th>9989</th>\n",
              "      <th>9990</th>\n",
              "      <th>9991</th>\n",
              "      <th>9992</th>\n",
              "      <th>9993</th>\n",
              "      <th>9994</th>\n",
              "      <th>9995</th>\n",
              "      <th>9996</th>\n",
              "      <th>9997</th>\n",
              "      <th>9998</th>\n",
              "      <th>9999</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Nadam</th>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adam</th>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Model1</th>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 10000 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0     1     2     3     4     5     ...  9994  9995  9996  9997  9998  9999\n",
              "Nadam      3     8     8     0     6     6  ...     3     3     3     5     4     7\n",
              "Adam       3     8     8     8     6     6  ...     3     3     5     5     1     7\n",
              "Model1     3     8     8     0     6     6  ...     3     3     3     5     4     7\n",
              "\n",
              "[3 rows x 10000 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbkiSyDodnRO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.stats import mode"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1w3Uw1edaFi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0805458a-fd19-4854-eff3-6df3c4e47af5"
      },
      "source": [
        "committee_score = accuracy_score(list(mode(results.T)[0])[0], y_test2)\n",
        "committee_score"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7695"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MJqQ1LOejk1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "a8dfa1c1-0297-4e0d-9633-d1f3280f81c4"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "conf_mx = confusion_matrix(y_test2, pred_nadam)\n",
        "conf_mx"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[810,   5,  42,  17,  19,   4,   9,   3,  74,  17],\n",
              "       [ 12, 854,   4,   6,   5,   4,   9,   1,  43,  62],\n",
              "       [ 65,   1, 615,  73,  92,  57,  63,  15,  16,   3],\n",
              "       [ 14,   3,  45, 652,  60, 125,  65,  17,  12,   7],\n",
              "       [ 15,   1,  42,  53, 795,  22,  39,  25,   8,   0],\n",
              "       [ 12,   1,  38, 209,  55, 641,  16,  22,   5,   1],\n",
              "       [  4,   1,  39,  60,  30,  11, 851,   2,   2,   0],\n",
              "       [ 14,   0,  42,  52,  81,  61,   7, 735,   1,   7],\n",
              "       [ 42,   8,  10,  14,   5,   3,   4,   1, 900,  13],\n",
              "       [ 36,  44,   7,  16,   7,   1,   8,   6,  33, 842]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aunXMg4Jfbih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_confusion_matrix(matrix):\n",
        "    \"\"\"If you prefer color and a colorbar\"\"\"\n",
        "    fig = plt.figure(figsize=(8,8))\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(matrix)\n",
        "    fig.colorbar(cax)"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqC8fghAgH5c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "e5c31af7-6d32-4b38-ebd4-e4657d7bbe4d"
      },
      "source": [
        "row_sums = conf_mx.sum(axis=1, keepdims=True)\n",
        "norm_conf_mx = conf_mx / row_sums\n",
        "np.fill_diagonal(norm_conf_mx, 0)\n",
        "plot_confusion_matrix(norm_conf_mx)"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xm2oyIsGfrWZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "2f813538-4a08-47f7-c864-add25f1e42d1"
      },
      "source": [
        "plt.matshow(norm_conf_mx, cmap=plt.cm.gray)\n",
        "plt.show()"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTDi7UGmgdXQ",
        "colab_type": "text"
      },
      "source": [
        "##### Чаще всего между собой путались 3 и 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1B0OkeMyFuN2",
        "colab_type": "text"
      },
      "source": [
        "### CIFAR 100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "In7wZuW7Lu4U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cb0d06df-7e8c-4de8-8545-9444ecdcb71f"
      },
      "source": [
        "load_model('./gdrive/My Drive/finuni/SNT/sifar100_nadam')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.sequential.Sequential at 0x7f08bfb2bdd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TS4Q6UhQFJ8u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "9971d119-113f-4675-b664-4815aeb98713"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow import keras\n",
        "import keras.layers as layers\n",
        "from keras.datasets import cifar10, cifar100\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPooling2D, Activation, BatchNormalization\n",
        "from keras.optimizers import SGD, Adam, Nadam\n",
        "from keras import regularizers\n",
        "\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "#model = load_model('./gdrive/My Drive/finuni/SNT/my_conv_model') # загрузка сохраненнлй модели\n",
        "#model.save('./gdrive/My Drive/finuni/SNT/my_conv_model')\n",
        "\n",
        "\n",
        "print(\"Setup Complete\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "4/4AGy4R4nCra80mz3Vg5AzFXY3n_nvsS3AR-hS4_ppB3ODTCTBQALKY0\n",
            "Mounted at /content/gdrive\n",
            "Setup Complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjG54XGuFRJJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9e2060f2-154b-44ae-f5d3-9e3ec2b84e53"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = cifar100.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTf5fuAvFeky",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "c5f3ee58-4ed1-4587-d83b-f6e442f36da1"
      },
      "source": [
        "idx = 155\n",
        "print(y_train[idx])\n",
        "plt.imshow(X_train[idx]);"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[29]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVXxdiq1FfDz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(42)\n",
        "NB_EPOCH = 200 \n",
        "BATCH_SIZE = 128 \n",
        "VERBOSE = 1 \n",
        "NB_CLASSES = 100\n",
        "OPTIMIZER = SGD()\n",
        "N_HIDDEN = 128\n",
        "VALIDATION_SPLIT = 0.2 \n",
        "\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
        "X_test2 = X_test.copy()\n",
        "y_test2 = y_test.copy()\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, NB_CLASSES)\n",
        "y_test = keras.utils.to_categorical(y_test, NB_CLASSES)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svJiYPQBFrDY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "780e4d27-b8bf-4b33-f238-89def7ea4ceb"
      },
      "source": [
        "print(X_train.shape[0], 'train_samples')\n",
        "print(X_test.shape[0], 'test_samples')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000 train_samples\n",
            "10000 test_samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUnuy0nLpfiN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(42)\n",
        "weight_decay = 0.0005\n",
        "\n",
        "model = Sequential()\n",
        "keras.Input(shape=(32,32,1)),\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512,kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(NB_CLASSES))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2N4LKyXFq_F1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0e260df2-dac6-4d4f-cb70-020259df86f8"
      },
      "source": [
        "callback = keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics='accuracy')\n",
        "\n",
        "model.fit(X_train, y_train, batch_size=100, epochs=130, verbose = 1, callbacks=[callback], validation_split=0.3)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "350/350 [==============================] - ETA: 0s - loss: 7.0399 - accuracy: 0.0242WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0031s vs `on_test_batch_end` time: 0.0108s). Check your callbacks.\n",
            "350/350 [==============================] - 26s 74ms/step - loss: 7.0399 - accuracy: 0.0242 - val_loss: 7.0774 - val_accuracy: 0.0193\n",
            "Epoch 2/200\n",
            "350/350 [==============================] - 26s 74ms/step - loss: 6.1484 - accuracy: 0.0500 - val_loss: 6.0468 - val_accuracy: 0.0385\n",
            "Epoch 3/200\n",
            "350/350 [==============================] - 26s 74ms/step - loss: 5.4996 - accuracy: 0.0790 - val_loss: 5.5634 - val_accuracy: 0.0607\n",
            "Epoch 4/200\n",
            "350/350 [==============================] - 26s 75ms/step - loss: 5.0298 - accuracy: 0.1023 - val_loss: 5.2760 - val_accuracy: 0.1048\n",
            "Epoch 5/200\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 4.6109 - accuracy: 0.1348 - val_loss: 4.6055 - val_accuracy: 0.1517\n",
            "Epoch 6/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 4.3377 - accuracy: 0.1600 - val_loss: 4.3864 - val_accuracy: 0.1541\n",
            "Epoch 7/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 4.2421 - accuracy: 0.1796 - val_loss: 4.2735 - val_accuracy: 0.1727\n",
            "Epoch 8/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 4.0693 - accuracy: 0.2089 - val_loss: 4.1486 - val_accuracy: 0.2006\n",
            "Epoch 9/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.9317 - accuracy: 0.2420 - val_loss: 4.1181 - val_accuracy: 0.2348\n",
            "Epoch 10/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.8851 - accuracy: 0.2588 - val_loss: 4.1589 - val_accuracy: 0.2276\n",
            "Epoch 11/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.8425 - accuracy: 0.2772 - val_loss: 4.0897 - val_accuracy: 0.2467\n",
            "Epoch 12/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.8287 - accuracy: 0.2893 - val_loss: 4.1626 - val_accuracy: 0.2521\n",
            "Epoch 13/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.8183 - accuracy: 0.3054 - val_loss: 3.8888 - val_accuracy: 0.2927\n",
            "Epoch 14/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.8149 - accuracy: 0.3157 - val_loss: 4.0090 - val_accuracy: 0.2933\n",
            "Epoch 15/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.7869 - accuracy: 0.3317 - val_loss: 3.8526 - val_accuracy: 0.3332\n",
            "Epoch 16/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.7887 - accuracy: 0.3381 - val_loss: 4.1356 - val_accuracy: 0.3218\n",
            "Epoch 17/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.7757 - accuracy: 0.3528 - val_loss: 4.0909 - val_accuracy: 0.3209\n",
            "Epoch 18/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.7733 - accuracy: 0.3597 - val_loss: 3.8161 - val_accuracy: 0.3633\n",
            "Epoch 19/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.7421 - accuracy: 0.3710 - val_loss: 3.8917 - val_accuracy: 0.3471\n",
            "Epoch 20/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.7416 - accuracy: 0.3766 - val_loss: 3.9836 - val_accuracy: 0.3550\n",
            "Epoch 21/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.7341 - accuracy: 0.3864 - val_loss: 4.1315 - val_accuracy: 0.3392\n",
            "Epoch 22/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.7384 - accuracy: 0.3924 - val_loss: 3.8897 - val_accuracy: 0.3791\n",
            "Epoch 23/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.7089 - accuracy: 0.4025 - val_loss: 4.1345 - val_accuracy: 0.3312\n",
            "Epoch 24/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.6999 - accuracy: 0.4089 - val_loss: 3.8058 - val_accuracy: 0.4063\n",
            "Epoch 25/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.6882 - accuracy: 0.4133 - val_loss: 4.0336 - val_accuracy: 0.3649\n",
            "Epoch 26/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.6651 - accuracy: 0.4171 - val_loss: 4.0834 - val_accuracy: 0.3724\n",
            "Epoch 27/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.6589 - accuracy: 0.4285 - val_loss: 3.9573 - val_accuracy: 0.3839\n",
            "Epoch 28/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.6407 - accuracy: 0.4320 - val_loss: 3.8391 - val_accuracy: 0.4039\n",
            "Epoch 29/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.6504 - accuracy: 0.4314 - val_loss: 3.7779 - val_accuracy: 0.4213\n",
            "Epoch 30/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.6072 - accuracy: 0.4415 - val_loss: 3.8067 - val_accuracy: 0.4187\n",
            "Epoch 31/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.5978 - accuracy: 0.4491 - val_loss: 3.8756 - val_accuracy: 0.4099\n",
            "Epoch 32/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.5758 - accuracy: 0.4522 - val_loss: 3.7902 - val_accuracy: 0.4245\n",
            "Epoch 33/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.5740 - accuracy: 0.4553 - val_loss: 3.7105 - val_accuracy: 0.4341\n",
            "Epoch 34/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.5388 - accuracy: 0.4626 - val_loss: 3.8119 - val_accuracy: 0.4202\n",
            "Epoch 35/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.5325 - accuracy: 0.4646 - val_loss: 3.6965 - val_accuracy: 0.4475\n",
            "Epoch 36/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.5043 - accuracy: 0.4713 - val_loss: 3.7871 - val_accuracy: 0.4487\n",
            "Epoch 37/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.4937 - accuracy: 0.4741 - val_loss: 3.8951 - val_accuracy: 0.4224\n",
            "Epoch 38/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.4749 - accuracy: 0.4786 - val_loss: 3.7773 - val_accuracy: 0.4359\n",
            "Epoch 39/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.4812 - accuracy: 0.4788 - val_loss: 3.6842 - val_accuracy: 0.4469\n",
            "Epoch 40/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.4685 - accuracy: 0.4796 - val_loss: 3.7845 - val_accuracy: 0.4315\n",
            "Epoch 41/200\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 3.4504 - accuracy: 0.4865 - val_loss: 3.7020 - val_accuracy: 0.4439\n",
            "Epoch 42/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.4275 - accuracy: 0.4898 - val_loss: 3.8080 - val_accuracy: 0.4335\n",
            "Epoch 43/200\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 3.4281 - accuracy: 0.4943 - val_loss: 4.1304 - val_accuracy: 0.3883\n",
            "Epoch 44/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.4093 - accuracy: 0.4937 - val_loss: 3.8622 - val_accuracy: 0.4195\n",
            "Epoch 45/200\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 3.4088 - accuracy: 0.4983 - val_loss: 3.5464 - val_accuracy: 0.4785\n",
            "Epoch 46/200\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 3.3856 - accuracy: 0.5033 - val_loss: 3.7530 - val_accuracy: 0.4400\n",
            "Epoch 47/200\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 3.3786 - accuracy: 0.5024 - val_loss: 3.8534 - val_accuracy: 0.4281\n",
            "Epoch 48/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.3729 - accuracy: 0.5040 - val_loss: 3.7005 - val_accuracy: 0.4517\n",
            "Epoch 49/200\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 3.3584 - accuracy: 0.5095 - val_loss: 3.7010 - val_accuracy: 0.4446\n",
            "Epoch 50/200\n",
            "350/350 [==============================] - 27s 77ms/step - loss: 3.3373 - accuracy: 0.5103 - val_loss: 3.6465 - val_accuracy: 0.4632\n",
            "Epoch 51/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.3528 - accuracy: 0.5092 - val_loss: 3.6057 - val_accuracy: 0.4697\n",
            "Epoch 52/200\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 3.3335 - accuracy: 0.5105 - val_loss: 3.6569 - val_accuracy: 0.4576\n",
            "Epoch 53/200\n",
            "350/350 [==============================] - 27s 77ms/step - loss: 3.3064 - accuracy: 0.5162 - val_loss: 3.5678 - val_accuracy: 0.4729\n",
            "Epoch 54/200\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 3.3130 - accuracy: 0.5157 - val_loss: 3.7221 - val_accuracy: 0.4549\n",
            "Epoch 55/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.3066 - accuracy: 0.5157 - val_loss: 3.7473 - val_accuracy: 0.4539\n",
            "Epoch 56/200\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 3.2896 - accuracy: 0.5171 - val_loss: 3.6155 - val_accuracy: 0.4749\n",
            "Epoch 57/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.2775 - accuracy: 0.5235 - val_loss: 3.6586 - val_accuracy: 0.4640\n",
            "Epoch 58/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.2866 - accuracy: 0.5211 - val_loss: 3.8320 - val_accuracy: 0.4264\n",
            "Epoch 59/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.2707 - accuracy: 0.5270 - val_loss: 3.5529 - val_accuracy: 0.4767\n",
            "Epoch 60/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.2747 - accuracy: 0.5269 - val_loss: 3.5801 - val_accuracy: 0.4763\n",
            "Epoch 61/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.2575 - accuracy: 0.5309 - val_loss: 3.6960 - val_accuracy: 0.4571\n",
            "Epoch 62/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.2563 - accuracy: 0.5288 - val_loss: 3.7196 - val_accuracy: 0.4511\n",
            "Epoch 63/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.2555 - accuracy: 0.5302 - val_loss: 3.5592 - val_accuracy: 0.4835\n",
            "Epoch 64/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.2385 - accuracy: 0.5325 - val_loss: 3.4476 - val_accuracy: 0.5003\n",
            "Epoch 65/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.2447 - accuracy: 0.5347 - val_loss: 3.7743 - val_accuracy: 0.4530\n",
            "Epoch 66/200\n",
            "350/350 [==============================] - 27s 77ms/step - loss: 3.2145 - accuracy: 0.5358 - val_loss: 3.5007 - val_accuracy: 0.4899\n",
            "Epoch 67/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.2391 - accuracy: 0.5321 - val_loss: 3.5049 - val_accuracy: 0.4929\n",
            "Epoch 68/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.1983 - accuracy: 0.5393 - val_loss: 3.4871 - val_accuracy: 0.4851\n",
            "Epoch 69/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.2038 - accuracy: 0.5400 - val_loss: 3.5426 - val_accuracy: 0.4923\n",
            "Epoch 70/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.2098 - accuracy: 0.5419 - val_loss: 3.6411 - val_accuracy: 0.4659\n",
            "Epoch 71/200\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.2015 - accuracy: 0.5461 - val_loss: 3.6861 - val_accuracy: 0.4659\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0790743d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiHjCgcKkGQT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bc83da99-939e-433f-a329-0a12af0f6e28"
      },
      "source": [
        "model.save('./gdrive/My Drive/finuni/SNT/sifar100_nadam')"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./gdrive/My Drive/finuni/SNT/sifar100_nadam/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIDWlmH2c7N-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "35e78866-d151-4875-f5de-7cc93daaa4f6"
      },
      "source": [
        "callback = keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n",
        "\n",
        "model.fit(X_train, y_train, batch_size=100, epochs=130, verbose = 1, callbacks=[callback], validation_split=0.3)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/130\n",
            "  2/350 [..............................] - ETA: 16s - loss: 3.0767 - accuracy: 0.5450WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0372s vs `on_train_batch_end` time: 0.0583s). Check your callbacks.\n",
            "350/350 [==============================] - ETA: 0s - loss: 3.1997 - accuracy: 0.5431WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0034s vs `on_test_batch_end` time: 0.0111s). Check your callbacks.\n",
            "350/350 [==============================] - 26s 74ms/step - loss: 3.1997 - accuracy: 0.5431 - val_loss: 3.3800 - val_accuracy: 0.5153\n",
            "Epoch 2/130\n",
            "350/350 [==============================] - 26s 74ms/step - loss: 3.1882 - accuracy: 0.5427 - val_loss: 3.6704 - val_accuracy: 0.4641\n",
            "Epoch 3/130\n",
            "350/350 [==============================] - 26s 74ms/step - loss: 3.1803 - accuracy: 0.5461 - val_loss: 3.5460 - val_accuracy: 0.4939\n",
            "Epoch 4/130\n",
            "350/350 [==============================] - 26s 75ms/step - loss: 3.1890 - accuracy: 0.5413 - val_loss: 3.6532 - val_accuracy: 0.4688\n",
            "Epoch 5/130\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 3.1815 - accuracy: 0.5453 - val_loss: 3.5450 - val_accuracy: 0.4865\n",
            "Epoch 6/130\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 3.1768 - accuracy: 0.5453 - val_loss: 3.5056 - val_accuracy: 0.4987\n",
            "Epoch 7/130\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 3.1663 - accuracy: 0.5501 - val_loss: 3.5079 - val_accuracy: 0.4952\n",
            "Epoch 8/130\n",
            "350/350 [==============================] - 26s 75ms/step - loss: 3.1504 - accuracy: 0.5547 - val_loss: 3.3934 - val_accuracy: 0.5099\n",
            "Epoch 9/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.1222 - accuracy: 0.5571 - val_loss: 3.5065 - val_accuracy: 0.4952\n",
            "Epoch 10/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.1577 - accuracy: 0.5504 - val_loss: 3.5492 - val_accuracy: 0.4795\n",
            "Epoch 11/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.1435 - accuracy: 0.5511 - val_loss: 3.5702 - val_accuracy: 0.4817\n",
            "Epoch 12/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.1152 - accuracy: 0.5575 - val_loss: 3.4549 - val_accuracy: 0.5043\n",
            "Epoch 13/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.1352 - accuracy: 0.5547 - val_loss: 3.4642 - val_accuracy: 0.4989\n",
            "Epoch 14/130\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 3.1221 - accuracy: 0.5585 - val_loss: 3.4455 - val_accuracy: 0.5013\n",
            "Epoch 15/130\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 3.1304 - accuracy: 0.5556 - val_loss: 3.5093 - val_accuracy: 0.5045\n",
            "Epoch 16/130\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 3.1228 - accuracy: 0.5589 - val_loss: 3.3817 - val_accuracy: 0.5185\n",
            "Epoch 17/130\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 3.1006 - accuracy: 0.5645 - val_loss: 3.4818 - val_accuracy: 0.4934\n",
            "Epoch 18/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.1165 - accuracy: 0.5571 - val_loss: 3.4468 - val_accuracy: 0.5043\n",
            "Epoch 19/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.0901 - accuracy: 0.5621 - val_loss: 3.4713 - val_accuracy: 0.4941\n",
            "Epoch 20/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.1105 - accuracy: 0.5620 - val_loss: 3.5946 - val_accuracy: 0.4857\n",
            "Epoch 21/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.0912 - accuracy: 0.5645 - val_loss: 3.3902 - val_accuracy: 0.5135\n",
            "Epoch 22/130\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 3.0970 - accuracy: 0.5603 - val_loss: 3.5028 - val_accuracy: 0.5001\n",
            "Epoch 23/130\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 3.1021 - accuracy: 0.5621 - val_loss: 3.5194 - val_accuracy: 0.4883\n",
            "Epoch 24/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.1012 - accuracy: 0.5633 - val_loss: 3.4480 - val_accuracy: 0.4985\n",
            "Epoch 25/130\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 3.1052 - accuracy: 0.5602 - val_loss: 3.5227 - val_accuracy: 0.4943\n",
            "Epoch 26/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.0671 - accuracy: 0.5717 - val_loss: 3.5145 - val_accuracy: 0.4979\n",
            "Epoch 27/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.0861 - accuracy: 0.5642 - val_loss: 3.3847 - val_accuracy: 0.5171\n",
            "Epoch 28/130\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 3.0776 - accuracy: 0.5660 - val_loss: 3.4399 - val_accuracy: 0.5059\n",
            "Epoch 29/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.0749 - accuracy: 0.5694 - val_loss: 3.4463 - val_accuracy: 0.5042\n",
            "Epoch 30/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.0736 - accuracy: 0.5699 - val_loss: 3.4103 - val_accuracy: 0.5115\n",
            "Epoch 31/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.0855 - accuracy: 0.5623 - val_loss: 3.4557 - val_accuracy: 0.5055\n",
            "Epoch 32/130\n",
            "350/350 [==============================] - 26s 75ms/step - loss: 3.0659 - accuracy: 0.5683 - val_loss: 3.4620 - val_accuracy: 0.5087\n",
            "Epoch 33/130\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 3.0657 - accuracy: 0.5714 - val_loss: 3.4052 - val_accuracy: 0.5118\n",
            "Epoch 34/130\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 3.0714 - accuracy: 0.5685 - val_loss: 3.4026 - val_accuracy: 0.5207\n",
            "Epoch 35/130\n",
            "350/350 [==============================] - 27s 77ms/step - loss: 3.0527 - accuracy: 0.5751 - val_loss: 3.5563 - val_accuracy: 0.4907\n",
            "Epoch 36/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.0503 - accuracy: 0.5735 - val_loss: 3.4205 - val_accuracy: 0.5122\n",
            "Epoch 37/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.0682 - accuracy: 0.5712 - val_loss: 3.4541 - val_accuracy: 0.5072\n",
            "Epoch 38/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.0507 - accuracy: 0.5744 - val_loss: 3.5818 - val_accuracy: 0.4931\n",
            "Epoch 39/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.0535 - accuracy: 0.5685 - val_loss: 3.3827 - val_accuracy: 0.5207\n",
            "Epoch 40/130\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 3.0569 - accuracy: 0.5693 - val_loss: 3.5734 - val_accuracy: 0.4881\n",
            "Epoch 41/130\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 3.0371 - accuracy: 0.5738 - val_loss: 3.4751 - val_accuracy: 0.4940\n",
            "Epoch 42/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.0462 - accuracy: 0.5710 - val_loss: 3.3103 - val_accuracy: 0.5359\n",
            "Epoch 43/130\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 3.0475 - accuracy: 0.5692 - val_loss: 3.5142 - val_accuracy: 0.4891\n",
            "Epoch 44/130\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 3.0372 - accuracy: 0.5731 - val_loss: 3.3581 - val_accuracy: 0.5143\n",
            "Epoch 45/130\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 3.0337 - accuracy: 0.5741 - val_loss: 3.3380 - val_accuracy: 0.5203\n",
            "Epoch 46/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.0294 - accuracy: 0.5737 - val_loss: 3.3863 - val_accuracy: 0.5135\n",
            "Epoch 47/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.0295 - accuracy: 0.5781 - val_loss: 3.2989 - val_accuracy: 0.5299\n",
            "Epoch 48/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.0220 - accuracy: 0.5778 - val_loss: 3.5225 - val_accuracy: 0.4945\n",
            "Epoch 49/130\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 3.0263 - accuracy: 0.5795 - val_loss: 3.5448 - val_accuracy: 0.4806\n",
            "Epoch 50/130\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 3.0236 - accuracy: 0.5750 - val_loss: 3.5882 - val_accuracy: 0.4920\n",
            "Epoch 51/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.0291 - accuracy: 0.5764 - val_loss: 3.6132 - val_accuracy: 0.4769\n",
            "Epoch 52/130\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 2.9990 - accuracy: 0.5808 - val_loss: 3.3521 - val_accuracy: 0.5163\n",
            "Epoch 53/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.0122 - accuracy: 0.5791 - val_loss: 3.4955 - val_accuracy: 0.5021\n",
            "Epoch 54/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.0180 - accuracy: 0.5799 - val_loss: 3.3196 - val_accuracy: 0.5315\n",
            "Epoch 55/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 2.9951 - accuracy: 0.5820 - val_loss: 3.4129 - val_accuracy: 0.5162\n",
            "Epoch 56/130\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 3.0268 - accuracy: 0.5782 - val_loss: 3.5043 - val_accuracy: 0.4945\n",
            "Epoch 57/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 3.0158 - accuracy: 0.5733 - val_loss: 3.5562 - val_accuracy: 0.4975\n",
            "Epoch 58/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 2.9954 - accuracy: 0.5843 - val_loss: 3.3619 - val_accuracy: 0.5225\n",
            "Epoch 59/130\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 3.0025 - accuracy: 0.5813 - val_loss: 3.4055 - val_accuracy: 0.5099\n",
            "Epoch 60/130\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 3.0126 - accuracy: 0.5786 - val_loss: 3.3952 - val_accuracy: 0.5167\n",
            "Epoch 61/130\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 3.0047 - accuracy: 0.5795 - val_loss: 3.3519 - val_accuracy: 0.5238\n",
            "Epoch 62/130\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 2.9833 - accuracy: 0.5873 - val_loss: 3.4536 - val_accuracy: 0.5084\n",
            "Epoch 63/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 2.9933 - accuracy: 0.5800 - val_loss: 3.2580 - val_accuracy: 0.5359\n",
            "Epoch 64/130\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 2.9853 - accuracy: 0.5849 - val_loss: 3.3102 - val_accuracy: 0.5323\n",
            "Epoch 65/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 2.9818 - accuracy: 0.5880 - val_loss: 3.3035 - val_accuracy: 0.5344\n",
            "Epoch 66/130\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 2.9928 - accuracy: 0.5834 - val_loss: 3.3445 - val_accuracy: 0.5160\n",
            "Epoch 67/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 2.9818 - accuracy: 0.5850 - val_loss: 3.3317 - val_accuracy: 0.5208\n",
            "Epoch 68/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 2.9905 - accuracy: 0.5832 - val_loss: 3.3820 - val_accuracy: 0.5152\n",
            "Epoch 69/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 2.9714 - accuracy: 0.5875 - val_loss: 3.6111 - val_accuracy: 0.4749\n",
            "Epoch 70/130\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 2.9795 - accuracy: 0.5853 - val_loss: 3.4089 - val_accuracy: 0.5136\n",
            "Epoch 71/130\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 2.9816 - accuracy: 0.5866 - val_loss: 3.3208 - val_accuracy: 0.5295\n",
            "Epoch 72/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 2.9747 - accuracy: 0.5875 - val_loss: 3.3837 - val_accuracy: 0.5141\n",
            "Epoch 73/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 2.9767 - accuracy: 0.5865 - val_loss: 3.5095 - val_accuracy: 0.5062\n",
            "Epoch 74/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 2.9587 - accuracy: 0.5934 - val_loss: 3.3857 - val_accuracy: 0.5174\n",
            "Epoch 75/130\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 2.9636 - accuracy: 0.5891 - val_loss: 3.3938 - val_accuracy: 0.5118\n",
            "Epoch 76/130\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 2.9829 - accuracy: 0.5851 - val_loss: 3.2841 - val_accuracy: 0.5345\n",
            "Epoch 77/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 2.9655 - accuracy: 0.5844 - val_loss: 3.4839 - val_accuracy: 0.4916\n",
            "Epoch 78/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 2.9748 - accuracy: 0.5878 - val_loss: 3.4266 - val_accuracy: 0.5127\n",
            "Epoch 79/130\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 2.9773 - accuracy: 0.5882 - val_loss: 3.4768 - val_accuracy: 0.5039\n",
            "Epoch 80/130\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 2.9706 - accuracy: 0.5885 - val_loss: 3.4099 - val_accuracy: 0.5033\n",
            "Epoch 81/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 2.9513 - accuracy: 0.5888 - val_loss: 3.3094 - val_accuracy: 0.5285\n",
            "Epoch 82/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 2.9671 - accuracy: 0.5901 - val_loss: 3.3434 - val_accuracy: 0.5280\n",
            "Epoch 83/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 2.9667 - accuracy: 0.5891 - val_loss: 3.3872 - val_accuracy: 0.5169\n",
            "Epoch 84/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 2.9556 - accuracy: 0.5891 - val_loss: 3.3139 - val_accuracy: 0.5301\n",
            "Epoch 85/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 2.9530 - accuracy: 0.5931 - val_loss: 3.2856 - val_accuracy: 0.5341\n",
            "Epoch 86/130\n",
            "350/350 [==============================] - 26s 76ms/step - loss: 2.9611 - accuracy: 0.5893 - val_loss: 3.2904 - val_accuracy: 0.5355\n",
            "Epoch 87/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 2.9546 - accuracy: 0.5919 - val_loss: 3.3487 - val_accuracy: 0.5283\n",
            "Epoch 88/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 2.9648 - accuracy: 0.5916 - val_loss: 3.3213 - val_accuracy: 0.5312\n",
            "Epoch 89/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 2.9638 - accuracy: 0.5881 - val_loss: 3.4361 - val_accuracy: 0.5153\n",
            "Epoch 90/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 2.9583 - accuracy: 0.5928 - val_loss: 3.3895 - val_accuracy: 0.5202\n",
            "Epoch 91/130\n",
            "350/350 [==============================] - 27s 76ms/step - loss: 2.9546 - accuracy: 0.5853 - val_loss: 3.4473 - val_accuracy: 0.5095\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f079d5995c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNInFAqi0dwg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d0b14bee-98da-48e7-f727-0e078acdd450"
      },
      "source": [
        "model.save('./gdrive/My Drive/finuni/SNT/sifar100_nadam_best')"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./gdrive/My Drive/finuni/SNT/sifar100_nadam_best/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TU6ZQJxjeOx7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "outputId": "3e0e4685-31eb-4f33-85f8-44378d22fd8e"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=150, epochs=50, verbose = 1, callbacks=[callback], validation_split=0.3)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "234/234 [==============================] - ETA: 0s - loss: 2.6525 - accuracy: 0.6471WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0038s vs `on_test_batch_end` time: 0.0141s). Check your callbacks.\n",
            "234/234 [==============================] - 22s 96ms/step - loss: 2.6525 - accuracy: 0.6471 - val_loss: 3.0565 - val_accuracy: 0.5578\n",
            "Epoch 2/50\n",
            "234/234 [==============================] - 22s 93ms/step - loss: 2.5824 - accuracy: 0.6475 - val_loss: 3.1502 - val_accuracy: 0.5379\n",
            "Epoch 3/50\n",
            "234/234 [==============================] - 22s 94ms/step - loss: 2.5811 - accuracy: 0.6427 - val_loss: 3.0954 - val_accuracy: 0.5532\n",
            "Epoch 4/50\n",
            "234/234 [==============================] - 22s 95ms/step - loss: 2.5819 - accuracy: 0.6428 - val_loss: 3.0965 - val_accuracy: 0.5521\n",
            "Epoch 5/50\n",
            "234/234 [==============================] - 22s 95ms/step - loss: 2.5735 - accuracy: 0.6450 - val_loss: 3.1286 - val_accuracy: 0.5487\n",
            "Epoch 6/50\n",
            "234/234 [==============================] - 22s 96ms/step - loss: 2.5872 - accuracy: 0.6429 - val_loss: 3.2890 - val_accuracy: 0.5259\n",
            "Epoch 7/50\n",
            "234/234 [==============================] - 22s 96ms/step - loss: 2.6087 - accuracy: 0.6389 - val_loss: 3.1426 - val_accuracy: 0.5435\n",
            "Epoch 8/50\n",
            "234/234 [==============================] - 22s 96ms/step - loss: 2.5852 - accuracy: 0.6448 - val_loss: 3.1990 - val_accuracy: 0.5327\n",
            "Epoch 9/50\n",
            "234/234 [==============================] - 22s 96ms/step - loss: 2.5866 - accuracy: 0.6433 - val_loss: 3.1099 - val_accuracy: 0.5479\n",
            "Epoch 10/50\n",
            "234/234 [==============================] - 22s 96ms/step - loss: 2.6133 - accuracy: 0.6388 - val_loss: 3.0725 - val_accuracy: 0.5616\n",
            "Epoch 11/50\n",
            "234/234 [==============================] - 22s 96ms/step - loss: 2.6015 - accuracy: 0.6452 - val_loss: 3.1252 - val_accuracy: 0.5537\n",
            "Epoch 12/50\n",
            "234/234 [==============================] - 22s 96ms/step - loss: 2.5995 - accuracy: 0.6428 - val_loss: 3.2463 - val_accuracy: 0.5340\n",
            "Epoch 13/50\n",
            "234/234 [==============================] - 22s 96ms/step - loss: 2.5982 - accuracy: 0.6448 - val_loss: 3.2207 - val_accuracy: 0.5359\n",
            "Epoch 14/50\n",
            "234/234 [==============================] - 22s 96ms/step - loss: 2.6039 - accuracy: 0.6443 - val_loss: 3.1448 - val_accuracy: 0.5480\n",
            "Epoch 15/50\n",
            "234/234 [==============================] - 22s 96ms/step - loss: 2.5918 - accuracy: 0.6456 - val_loss: 3.1351 - val_accuracy: 0.5504\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f079d41c9e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdL0xGDZ_VvM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "226873ce-99b2-4b53-b356-d772f40cca66"
      },
      "source": [
        "model.save('./gdrive/My Drive/finuni/SNT/sifar100_nadam_best150')"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./gdrive/My Drive/finuni/SNT/sifar100_nadam_best150/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrM06GkB_OgY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "outputId": "c20208df-5f20-42e5-e4f8-09568c67585b"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=250, epochs=50, verbose = 1, callbacks=[callback], validation_split=0.3)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "140/140 [==============================] - 19s 136ms/step - loss: 2.3658 - accuracy: 0.6939 - val_loss: 2.8541 - val_accuracy: 0.5895\n",
            "Epoch 2/50\n",
            "140/140 [==============================] - 19s 134ms/step - loss: 2.2204 - accuracy: 0.7149 - val_loss: 2.8973 - val_accuracy: 0.5747\n",
            "Epoch 3/50\n",
            "140/140 [==============================] - 19s 133ms/step - loss: 2.1875 - accuracy: 0.7135 - val_loss: 2.9136 - val_accuracy: 0.5692\n",
            "Epoch 4/50\n",
            "140/140 [==============================] - 19s 132ms/step - loss: 2.1577 - accuracy: 0.7172 - val_loss: 2.9232 - val_accuracy: 0.5715\n",
            "Epoch 5/50\n",
            "140/140 [==============================] - 19s 132ms/step - loss: 2.1569 - accuracy: 0.7105 - val_loss: 2.9900 - val_accuracy: 0.5673\n",
            "Epoch 6/50\n",
            "140/140 [==============================] - 19s 133ms/step - loss: 2.1697 - accuracy: 0.7080 - val_loss: 2.9326 - val_accuracy: 0.5721\n",
            "Epoch 7/50\n",
            "140/140 [==============================] - 19s 133ms/step - loss: 2.1780 - accuracy: 0.7044 - val_loss: 2.9716 - val_accuracy: 0.5675\n",
            "Epoch 8/50\n",
            "140/140 [==============================] - 19s 133ms/step - loss: 2.1788 - accuracy: 0.7071 - val_loss: 3.0351 - val_accuracy: 0.5597\n",
            "Epoch 9/50\n",
            "140/140 [==============================] - 19s 133ms/step - loss: 2.1921 - accuracy: 0.7054 - val_loss: 3.0083 - val_accuracy: 0.5609\n",
            "Epoch 10/50\n",
            "140/140 [==============================] - 19s 133ms/step - loss: 2.1787 - accuracy: 0.7077 - val_loss: 2.9006 - val_accuracy: 0.5800\n",
            "Epoch 11/50\n",
            "140/140 [==============================] - 19s 133ms/step - loss: 2.1859 - accuracy: 0.7099 - val_loss: 3.0683 - val_accuracy: 0.5531\n",
            "Epoch 12/50\n",
            "140/140 [==============================] - 19s 133ms/step - loss: 2.1932 - accuracy: 0.7068 - val_loss: 3.0316 - val_accuracy: 0.5625\n",
            "Epoch 13/50\n",
            "140/140 [==============================] - 19s 133ms/step - loss: 2.1932 - accuracy: 0.7070 - val_loss: 2.9868 - val_accuracy: 0.5637\n",
            "Epoch 14/50\n",
            "140/140 [==============================] - 19s 133ms/step - loss: 2.1830 - accuracy: 0.7093 - val_loss: 2.9550 - val_accuracy: 0.5757\n",
            "Epoch 15/50\n",
            "140/140 [==============================] - 19s 133ms/step - loss: 2.2086 - accuracy: 0.7037 - val_loss: 3.0435 - val_accuracy: 0.5671\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f078f625a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-8rHysM--aq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b340ed13-a9ca-4eba-eba8-f70c4b228c90"
      },
      "source": [
        "model.save('./gdrive/My Drive/finuni/SNT/sifar100_nadam_best250')"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./gdrive/My Drive/finuni/SNT/sifar100_nadam_best250/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9FMZNsI_bM0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        },
        "outputId": "f35bb866-f143-4c47-af4f-70135f0d3c56"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=300, epochs=50, verbose = 1, callbacks=[callback], validation_split=0.3)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "117/117 [==============================] - 18s 157ms/step - loss: 2.1031 - accuracy: 0.7280 - val_loss: 2.8858 - val_accuracy: 0.5842\n",
            "Epoch 2/50\n",
            "117/117 [==============================] - 17s 147ms/step - loss: 2.0548 - accuracy: 0.7343 - val_loss: 2.8995 - val_accuracy: 0.5753\n",
            "Epoch 3/50\n",
            "117/117 [==============================] - 17s 148ms/step - loss: 2.0598 - accuracy: 0.7309 - val_loss: 2.9092 - val_accuracy: 0.5754\n",
            "Epoch 4/50\n",
            "117/117 [==============================] - 17s 149ms/step - loss: 2.0476 - accuracy: 0.7366 - val_loss: 2.9719 - val_accuracy: 0.5710\n",
            "Epoch 5/50\n",
            "117/117 [==============================] - 18s 150ms/step - loss: 2.0549 - accuracy: 0.7324 - val_loss: 2.9086 - val_accuracy: 0.5820\n",
            "Epoch 6/50\n",
            "117/117 [==============================] - 18s 151ms/step - loss: 2.0457 - accuracy: 0.7308 - val_loss: 2.9729 - val_accuracy: 0.5733\n",
            "Epoch 7/50\n",
            "117/117 [==============================] - 18s 152ms/step - loss: 2.0531 - accuracy: 0.7327 - val_loss: 2.8663 - val_accuracy: 0.5926\n",
            "Epoch 8/50\n",
            "117/117 [==============================] - 18s 153ms/step - loss: 2.0522 - accuracy: 0.7330 - val_loss: 2.9044 - val_accuracy: 0.5819\n",
            "Epoch 9/50\n",
            "117/117 [==============================] - 18s 154ms/step - loss: 2.0652 - accuracy: 0.7307 - val_loss: 2.9788 - val_accuracy: 0.5741\n",
            "Epoch 10/50\n",
            "117/117 [==============================] - 18s 154ms/step - loss: 2.0549 - accuracy: 0.7352 - val_loss: 2.9645 - val_accuracy: 0.5795\n",
            "Epoch 11/50\n",
            "117/117 [==============================] - 18s 154ms/step - loss: 2.0609 - accuracy: 0.7321 - val_loss: 2.9643 - val_accuracy: 0.5855\n",
            "Epoch 12/50\n",
            "117/117 [==============================] - 18s 154ms/step - loss: 2.0659 - accuracy: 0.7306 - val_loss: 2.8809 - val_accuracy: 0.5943\n",
            "Epoch 13/50\n",
            "117/117 [==============================] - 18s 154ms/step - loss: 2.0541 - accuracy: 0.7366 - val_loss: 3.0132 - val_accuracy: 0.5708\n",
            "Epoch 14/50\n",
            "117/117 [==============================] - 18s 154ms/step - loss: 2.0613 - accuracy: 0.7329 - val_loss: 2.9816 - val_accuracy: 0.5773\n",
            "Epoch 15/50\n",
            "117/117 [==============================] - 18s 154ms/step - loss: 2.0770 - accuracy: 0.7319 - val_loss: 3.1168 - val_accuracy: 0.5590\n",
            "Epoch 16/50\n",
            "117/117 [==============================] - 18s 154ms/step - loss: 2.0735 - accuracy: 0.7341 - val_loss: 3.0247 - val_accuracy: 0.5722\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f079d3a7518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMVi65lSDRIv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8dc743dd-1a88-4588-addf-d8b1c6733e54"
      },
      "source": [
        "model.save('./gdrive/My Drive/finuni/SNT/sifar100_nadam_best300')"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./gdrive/My Drive/finuni/SNT/sifar100_nadam_best300/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0I7VOQinXTza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = load_model('./gdrive/My Drive/finuni/SNT/sifar100_nadam_best300')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5wc85BIXmUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}